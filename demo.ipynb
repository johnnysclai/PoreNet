{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utility.util import normalize_points\n",
    "from utility.gms_matcher import GmsMatcher, DrawingType\n",
    "from utility.log_detector import log_detect\n",
    "from utility.models import create_loader, get_desc\n",
    "from utility import models\n",
    "\n",
    "n_channels, size = 3, 42\n",
    "affine = False\n",
    "with_scale, with_rotation = False, False\n",
    "device = 'cuda:0'\n",
    "pth_path = 'pretrained/PoreNet.pth'\n",
    "coordconv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1, img2 = cv2.imread('img/billgates1.jpg'), cv2.imread('img/billgates2.jpg')\n",
    "img1_gray, img2_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY), cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "size1 = (img1.shape[1], img1.shape[0])\n",
    "size2 = (img2.shape[1], img2.shape[0])\n",
    "h1, w1, _ = img1.shape\n",
    "h2, w2, _ = img2.shape\n",
    "print('Image1 shape: ', img1.shape)\n",
    "print('Image2 shape:', img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keypoint detection\n",
    "blobs_log1 = log_detect(img1_gray, eliminate=True)\n",
    "blobs_log2 = log_detect(img2_gray, eliminate=True)\n",
    "pts1, sigma1 = np.float32(blobs_log1[:, :2]), blobs_log1[:, 2]\n",
    "pts2, sigma2 = np.float32(blobs_log2[:, :2]), blobs_log2[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network and loader\n",
    "net = models.HardNet(n_channels, size, coordconv=coordconv, affine=affine)\n",
    "net.load_state_dict(torch.load(pth_path))\n",
    "print('{} is loaded'.format(pth_path))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "patch_loader1 = create_loader(img1, pts1, sigma1, in_c=n_channels, size=size, bs=4096, coordconv=coordconv)\n",
    "patch_loader2 = create_loader(img2, pts2, sigma2, in_c=n_channels, size=size, bs=4096, coordconv=coordconv)\n",
    "desc1 = get_desc(net, patch_loader1, len(sigma1), device)\n",
    "desc2 = get_desc(net, patch_loader2, len(sigma2), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "gms = GmsMatcher(None, matcher)\n",
    "pts1_norm, pts2_norm = [], []\n",
    "normalize_points(pts1, size1, pts1_norm)\n",
    "normalize_points(pts2, size2, pts2_norm)\n",
    "\n",
    "query = {'norm_kpts': pts2_norm, 'descs': desc2}\n",
    "gallery = {'norm_kpts': pts1_norm, 'descs': desc1}\n",
    "start_time = time.time()\n",
    "num_inliers = gms.match_from_kptdesc(query, gallery, with_scale, with_rotation, draw=True)\n",
    "print('No. of inliers: ', num_inliers)\n",
    "print(\"Used %s\" % (time.time() - start_time))\n",
    "output = gms.draw_matches_from_pts(img2, img1, pts2, pts1, DrawingType.LINES_AND_POINTS)\n",
    "output = output[:,:,::-1]\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "plt.imshow(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
